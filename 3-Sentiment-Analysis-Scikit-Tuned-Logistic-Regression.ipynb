{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a73a6c",
   "metadata": {},
   "source": [
    "# Hyperparameter-Tuned Logistic Regression for IMDb Sentiment Analysis**\n",
    "\n",
    "Summary of the notebook **`3-Sentiment-Analysis-Scikit-Tuned-Logistic-Regression.ipynb`**\n",
    "\n",
    "---\n",
    "### This notebook demonstrates a **focused sentiment analysis pipeline** using Scikit-learn, applying **hyperparameter tuning** to optimize a logistic regression model on the IMDb movie review dataset.\n",
    "\n",
    "1. **Data Acquisition & Preprocessing**\n",
    "\n",
    "   * Full IMDb dataset (50,000 reviews) downloaded and parsed from raw tar.gz format.\n",
    "   * Reviews labeled as positive (1) or negative (0) and shuffled.\n",
    "\n",
    "2. **Data Splitting**\n",
    "\n",
    "   * Dataset split into training and testing sets (80/20 split).\n",
    "\n",
    "3. **Pipeline Setup**\n",
    "\n",
    "   * A Scikit-learn `Pipeline` combining **TF-IDF vectorization** and **Logistic Regression**.\n",
    "\n",
    "4. **Grid Search for Hyperparameter Optimization**\n",
    "\n",
    "   * Conducted `GridSearchCV` across TF-IDF features and logistic regression regularization strength (`C`).\n",
    "   * Best config: `max_features=10000`, `ngram_range=(1,2)`, `C=1`.\n",
    "\n",
    "5. **Model Evaluation**\n",
    "\n",
    "   * **Test Accuracy:** 0.90\n",
    "   * **ROC AUC Score:** 0.9646\n",
    "   * Provided full classification report and confusion matrix.\n",
    "\n",
    "6. **Model Interpretation**\n",
    "\n",
    "   * Extracted and displayed top positive and negative words by learned coefficients.\n",
    "\n",
    "7. **User Interaction**\n",
    "\n",
    "   * Developed an interactive command-line tool for live movie review classification.\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Results Table\n",
    "\n",
    "| Model                       | Accuracy | File Name                                  | Any Brief Note                            |\n",
    "| --------------------------- | -------- | ------------------------------------------ | ----------------------------------------- |\n",
    "| Logistic Regression (Tuned) | 0.9000   | `3-Sentiment-Analysis-Scikit-Tuned-Logistic-Regression.ipynb` | GridSearchCV-tuned; high ROC AUC (0.9646) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d5e0e",
   "metadata": {},
   "source": [
    "# Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "KEMW5giyh2M6",
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1748530490987,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "KEMW5giyh2M6"
   },
   "outputs": [],
   "source": [
    "# # Mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87ec4f",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "_47xqKa_hjHp",
   "metadata": {
    "executionInfo": {
     "elapsed": 9889,
     "status": "ok",
     "timestamp": 1748530500880,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "_47xqKa_hjHp"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c134c",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "t96vJrrmhylJ",
   "metadata": {
    "executionInfo": {
     "elapsed": 30920,
     "status": "ok",
     "timestamp": 1748530531799,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "t96vJrrmhylJ"
   },
   "outputs": [],
   "source": [
    "# 1. Load Data\n",
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Download and extract dataset\n",
    "if not os.path.exists(\"aclImdb\"):\n",
    "    urllib.request.urlretrieve(url, \"aclImdb_v1.tar.gz\")\n",
    "    with tarfile.open(\"aclImdb_v1.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall()\n",
    "\n",
    "# Function to read reviews\n",
    "def load_imdb_data(data_dir):\n",
    "    data = {\"review\": [], \"sentiment\": []}\n",
    "    for label in [\"pos\", \"neg\"]:\n",
    "        sentiment = 1 if label == \"pos\" else 0\n",
    "        path = os.path.join(data_dir, label)\n",
    "        for file in os.listdir(path):\n",
    "            with open(os.path.join(path, file), encoding=\"utf-8\") as f:\n",
    "                data[\"review\"].append(f.read())\n",
    "                data[\"sentiment\"].append(sentiment)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "train_df = load_imdb_data(\"aclImdb/train\")\n",
    "test_df = load_imdb_data(\"aclImdb/test\")\n",
    "df = pd.concat([train_df, test_df])\n",
    "df = shuffle(df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23296cf5",
   "metadata": {},
   "source": [
    "# 2. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "SMJy5GENhyhP",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1748530531819,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "SMJy5GENhyhP"
   },
   "outputs": [],
   "source": [
    "# 2. Train-Test Split\n",
    "X = df['review']\n",
    "y = df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8458077",
   "metadata": {},
   "source": [
    "# 3. Pipeline Creation\n",
    "\n",
    "### **Brief Explanation of Each Step**\n",
    "\n",
    "* **`Pipeline([...])`**\n",
    "  *   Combines multiple preprocessing and modeling steps into a single, streamlined workflow. Ensures consistency and simplifies training and prediction.\n",
    "\n",
    "* **`('tfidf', TfidfVectorizer())`**\n",
    "  *   Handles both tokenization and vectorization internally. Converts raw text into numerical features using **Term Frequency–Inverse Document Frequency (TF-IDF)**, which reflects the importance of words relative to the entire corpus.\n",
    "\n",
    "* **`('clf', LogisticRegression(solver='liblinear'))`**\n",
    "  * Applies **Logistic Regression** as the classification algorithm.\n",
    "\n",
    "  * `solver='liblinear'` is suitable for smaller datasets and supports **L1/L2 regularization**, helping to prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9LeCRaOHiJgn",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1748530531820,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "9LeCRaOHiJgn"
   },
   "outputs": [],
   "source": [
    "# 3. Pipeline Creation\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),                       # does both tokenizing and vectorizing internally\n",
    "    ('clf', LogisticRegression(solver='liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c5d87b",
   "metadata": {},
   "source": [
    "# 4. Hyperparameter Tuning\n",
    "\n",
    "### **Brief Explanation of Each Step**\n",
    "\n",
    "* **`grid_params`**\n",
    "  * Defines a set of hyperparameter values to search over for both TF-IDF and Logistic Regression.\n",
    "\n",
    "* **`GridSearchCV(...)`**\n",
    "  * Performs cross-validated grid search to find the best combination of hyperparameters.\n",
    "\n",
    "* **`gs.fit(X_train, y_train)`**\n",
    "  * Trains models for all parameter combinations and selects the best based on validation accuracy.\n",
    "\n",
    "* **`gs.best_params_ / gs.best_score_`**\n",
    "  * Outputs the best parameters and corresponding cross-validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "INokLuP2iOSR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 455714,
     "status": "ok",
     "timestamp": 1748530987531,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "INokLuP2iOSR",
    "outputId": "08cd35c9-06e9-4785-9202-010a8a141a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Best Parameters: {'clf__C': 1, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2)}\n",
      "Best CV Accuracy: 0.8939499923676283\n"
     ]
    }
   ],
   "source": [
    "# 4. Hyperparameter Tuning\n",
    "grid_params = {\n",
    "    'tfidf__max_features': [5000, 10000],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'clf__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipeline, grid_params, cv=3, n_jobs=-1, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", gs.best_params_)\n",
    "print(\"Best CV Accuracy:\", gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YSfFX3Uqp6fb",
   "metadata": {
    "id": "YSfFX3Uqp6fb"
   },
   "source": [
    "### 🔍 Line-by-Line Explanation:\n",
    "\n",
    "#### **`Fitting 3 folds for each of 12 candidates, totalling 36 fits`**\n",
    "\n",
    "* You're using **3-fold cross-validation** (i.e., the training set is split into 3 parts, and each is used once as a validation set while the others are used for training).\n",
    "* You have **12 hyperparameter combinations** (candidates) to test.\n",
    "* Therefore, **36 model fits** (12 combinations × 3 folds) are performed.\n",
    "\n",
    "---\n",
    "\n",
    "#### **`Best Parameters: {'clf__C': 1, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2)}`**\n",
    "\n",
    "* These are the best hyperparameters found:\n",
    "\n",
    "  * `clf__C: 1`: The regularization strength for the Logistic Regression classifier. A moderate value, balancing bias and variance.\n",
    "  * `tfidf__max_features: 10000`: The TF-IDF vectorizer will use the top 10,000 most informative words.\n",
    "  * `tfidf__ngram_range: (1, 2)`: Both unigrams and bigrams (single words and two-word phrases) are included in the features.\n",
    "\n",
    "---\n",
    "\n",
    "#### **`Best CV Accuracy: 0.8939499923676283`**\n",
    "\n",
    "* The **cross-validated accuracy score** of the model using the best parameters above is approximately **89.4%**.\n",
    "* This score is based only on the training data split into 3 folds — it gives a reliable estimate of how well the model is expected to perform on unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary:\n",
    "\n",
    "This result tells you that after testing 12 different combinations of parameters for your sentiment classification pipeline:\n",
    "\n",
    "* The best model includes both unigrams and bigrams, limits features to 10,000, and uses a regularization strength of 1.\n",
    "* It achieves nearly **89.4% accuracy** in cross-validation, suggesting strong generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2207b611",
   "metadata": {},
   "source": [
    "# 5. Evaluate on Test Set\n",
    "\n",
    "### 🔹 **Brief Explanation of Each Step**\n",
    "\n",
    "* **`best_model = gs.best_estimator_`**\n",
    "  * Retrieves the best model found during grid search.\n",
    "\n",
    "* **`predict(X_test)` / `predict_proba(X_test)`**\n",
    "  * Makes predictions and estimates class probabilities on the test set.\n",
    "\n",
    "* **`accuracy_score(...)`**\n",
    "  * Measures overall test accuracy.\n",
    "\n",
    "* **`confusion_matrix(...)`**\n",
    "  * Shows counts of true/false positives and negatives.\n",
    "\n",
    "* **`classification_report(...)`**\n",
    "  * Displays precision, recall, F1-score, and support for each class.\n",
    "\n",
    "* **`roc_auc_score(...)`**\n",
    "  * Evaluates model's ability to distinguish between classes (higher = better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7w9Z0SybiRes",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5774,
     "status": "ok",
     "timestamp": 1748530993302,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "7w9Z0SybiRes",
    "outputId": "d0c28a53-8653-4664-ad46-d805ba88cc14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Test Accuracy: 0.9\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4469  531]\n",
      " [ 469 4531]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      5000\n",
      "           1       0.90      0.91      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.96458336\n"
     ]
    }
   ],
   "source": [
    "# 5. Evaluate on Test Set\n",
    "best_model = gs.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nBest Model Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mMaqW17OrGtm",
   "metadata": {
    "id": "mMaqW17OrGtm"
   },
   "source": [
    "# 6. Evaluation of the **best-performing sentiment analysis model** on the **test dataset** of 10,000 IMDB reviews\n",
    "\n",
    "### ✅ **1. Best Model Test Accuracy: `0.90`**\n",
    "\n",
    "* The model correctly classified **90% of all test reviews** (both positive and negative).\n",
    "* Out of 10,000 test samples, **9,000 were predicted correctly**, and **1,000 were misclassified**.\n",
    "\n",
    "### 📉 **2. Confusion Matrix:**\n",
    "\n",
    "```\n",
    "[[4469  531]\n",
    " [ 469 4531]]\n",
    "```\n",
    "\n",
    "|                         | Predicted Negative (0) | Predicted Positive (1) |\n",
    "| ----------------------- | ---------------------- | ---------------------- |\n",
    "| **Actual Negative (0)** | 4469 (True Negative)   | 531 (False Positive)   |\n",
    "| **Actual Positive (1)** | 469 (False Negative)   | 4531 (True Positive)   |\n",
    "\n",
    "#### Interpretation:\n",
    "\n",
    "* **4469 reviews** were correctly identified as negative.\n",
    "* **4531 reviews** were correctly identified as positive.\n",
    "* **531 negative reviews** were wrongly classified as positive.\n",
    "* **469 positive reviews** were wrongly classified as negative.\n",
    "\n",
    "### 📊 **3. Classification Report:**\n",
    "\n",
    "| Class                | Precision | Recall | F1-Score | Support |\n",
    "| -------------------- | --------- | ------ | -------- | ------- |\n",
    "| 0 (Negative)         | 0.91      | 0.89   | 0.90     | 5000    |\n",
    "| 1 (Positive)         | 0.90      | 0.91   | 0.90     | 5000    |\n",
    "| **Overall Accuracy** |           |        | **0.90** | 10000   |\n",
    "\n",
    "#### Metrics:\n",
    "\n",
    "* **Precision**: Of all reviews predicted as a class, how many were correct.\n",
    "* **Recall**: Of all actual reviews of a class, how many were captured.\n",
    "* **F1-Score**: The harmonic mean of precision and recall — a balanced measure.\n",
    "\n",
    "##### Balanced performance:\n",
    "\n",
    "* The model performs **similarly well** on both positive and negative reviews, with F1-scores of **0.90**.\n",
    "* There's **no significant bias** toward either class, which is ideal.\n",
    "\n",
    "\n",
    "### 📈 **4. ROC AUC Score: `0.9646`**\n",
    "\n",
    "* **ROC AUC** (Receiver Operating Characteristic - Area Under Curve) measures the model's ability to distinguish between the classes.\n",
    "* A value of **0.9646** is **excellent** (closer to 1 means better separability).\n",
    "\n",
    "#### What it means:\n",
    "\n",
    "* The model has a **96.5% chance of ranking a randomly chosen positive review higher than a negative one**.\n",
    "* This suggests the model outputs strong, confident probabilities — not just good hard predictions.\n",
    "\n",
    "### 🧠 Summary:\n",
    "\n",
    "* **90% accuracy** on test data means the model generalizes well.\n",
    "* **Balanced precision and recall** across both classes.\n",
    "* **High ROC AUC** shows strong discriminative ability.\n",
    "* Only \\~5–6% of each class was misclassified — overall, a **very effective sentiment classifier**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e62bba",
   "metadata": {},
   "source": [
    "# 7. View Top Words by Coefficient\n",
    "\n",
    "### 🔹 **Brief Explanation of Each Step**\n",
    "\n",
    "* **`show_top_features(...)`**\n",
    "  * Displays the words with the strongest influence on the model’s predictions.\n",
    "\n",
    "* **`vectorizer.get_feature_names_out()`**\n",
    "  * Retrieves the vocabulary (all words used in the model).\n",
    "\n",
    "* **`classifier.coef_`**\n",
    "  * Contains **model coefficients**, which indicate how much each word contributes to predicting the positive or negative class:\n",
    "\n",
    "  * **Positive coefficients** = push prediction toward the positive class\n",
    "  * **Negative coefficients** = push prediction toward the negative class\n",
    "\n",
    "* **`np.argsort(...)`**\n",
    "  * Sorts the coefficients to find the top positively and negatively weighted words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lZKxwtPAiSiE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1748530993327,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "lZKxwtPAiSiE",
    "outputId": "5a5d7b11-b141-45d1-f5dc-07e8d8603976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Positive Words:\n",
      "['great' 'excellent' 'amazing' 'perfect' 'wonderful' 'today' 'fun' 'loved'\n",
      " 'brilliant' 'hilarious' 'best' 'superb' 'the best' 'definitely'\n",
      " 'enjoyable' 'especially' 'bit' 'fantastic' 'favorite' 'enjoyed']\n",
      "\n",
      "Top Negative Words:\n",
      "['worst' 'bad' 'awful' 'boring' 'the worst' 'poor' 'waste' 'terrible'\n",
      " 'nothing' 'worse' 'dull' 'horrible' 'stupid' 'poorly' 'disappointing'\n",
      " 'unfortunately' 'lame' 'annoying' 'disappointment' 'fails']\n"
     ]
    }
   ],
   "source": [
    "# 7. View Top Words by Coefficient\n",
    "def show_top_features(vectorizer, classifier, n=20):\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "    coef = classifier.coef_.flatten()\n",
    "    top_pos = np.argsort(coef)[-n:]\n",
    "    top_neg = np.argsort(coef)[:n]\n",
    "\n",
    "    print(\"\\nTop Positive Words:\")\n",
    "    print(feature_names[top_pos][::-1])\n",
    "    print(\"\\nTop Negative Words:\")\n",
    "    print(feature_names[top_neg])\n",
    "\n",
    "show_top_features(best_model.named_steps['tfidf'], best_model.named_steps['clf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf69d7",
   "metadata": {},
   "source": [
    "# 8. Interactive sentiment prediction function, incorporating user interaction and model behavior:\n",
    "\n",
    "### 🔹 **Brief Explanation of Each Step**\n",
    "\n",
    "* **`predict_sentiment_interactive(...)`**\n",
    "  * Provides a loop for users to enter reviews and receive real-time sentiment predictions.\n",
    "\n",
    "* **`pipeline.predict(...)`**\n",
    "  * Uses the trained model to classify the sentiment (positive or negative).\n",
    "\n",
    "* **`pipeline.predict_proba(...)`**\n",
    "  * Returns class probabilities to estimate **confidence** in the prediction.\n",
    "\n",
    "* **`textwrap.fill(...)`**\n",
    "  * Neatly formats long reviews for easier reading in the console or notebook.\n",
    "\n",
    "* **Interactive Loop**\n",
    "  * Continues until the user types `'exit'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbUQj2ohn4JT",
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1748531914873,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "dbUQj2ohn4JT"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment_interactive(pipeline, width=100):\n",
    "    while True:\n",
    "        review_text = input(\"\\nEnter a movie review (or type 'exit' to quit): \")\n",
    "        if review_text.lower() == 'exit':\n",
    "            print(\"Exiting sentiment analysis. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        prediction = pipeline.predict([review_text])[0]\n",
    "        probability = pipeline.predict_proba([review_text])[0]\n",
    "\n",
    "        sentiment = \"Positive 😊\" if prediction == 1 else \"Negative 😞\"\n",
    "        confidence = round(max(probability) * 100, 2)\n",
    "\n",
    "        # Wrap the text for display in notebook\n",
    "        wrapped_review = textwrap.fill(review_text, width=width)\n",
    "\n",
    "        print(\"\\n📝 Review:\")\n",
    "        print(wrapped_review)\n",
    "        print(f\"\\n✅ Sentiment: {sentiment}\")\n",
    "        print(f\"📊 Confidence: {confidence}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d84c7",
   "metadata": {},
   "source": [
    "# 9. Interactive tool\n",
    "\n",
    "### 🔹 **Brief Explanation of This Step**\n",
    "\n",
    "* **`predict_sentiment_interactive(best_model)`**\n",
    "  * Launches the interactive tool, allowing users to enter custom movie reviews and get real-time sentiment predictions with confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zPz9A_aBiZve",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zPz9A_aBiZve",
    "outputId": "e73b3bc9-d9b3-48e7-b4e8-f202460eadd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Review:\n",
      "HI there!\n",
      "\n",
      "✅ Sentiment: Negative 😞\n",
      "📊 Confidence: 67.32%\n",
      "\n",
      "📝 Review:\n",
      "What a fantastic mobie!\n",
      "\n",
      "✅ Sentiment: Positive 😊\n",
      "📊 Confidence: 96.07%\n",
      "\n",
      "📝 Review:\n",
      "What a fantastic movie! Are you kidding? I will not recommend it\n",
      "\n",
      "✅ Sentiment: Positive 😊\n",
      "📊 Confidence: 72.06%\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Run it\n",
    "predict_sentiment_interactive(best_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
