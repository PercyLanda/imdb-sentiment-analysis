{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a73a6c",
   "metadata": {},
   "source": [
    "Summary of the notebook **`4c-Sentiment-Analysis-Scikit-Learn.ipynb`**\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **Summary: Hyperparameter-Tuned Logistic Regression for IMDb Sentiment Analysis**\n",
    "\n",
    "This notebook demonstrates a **focused sentiment analysis pipeline** using Scikit-learn, applying **hyperparameter tuning** to optimize a logistic regression model on the IMDb movie review dataset.\n",
    "\n",
    "1. **Data Acquisition & Preprocessing**\n",
    "\n",
    "   * Full IMDb dataset (50,000 reviews) downloaded and parsed from raw tar.gz format.\n",
    "   * Reviews labeled as positive (1) or negative (0) and shuffled.\n",
    "\n",
    "2. **Data Splitting**\n",
    "\n",
    "   * Dataset split into training and testing sets (80/20 split).\n",
    "\n",
    "3. **Pipeline Setup**\n",
    "\n",
    "   * A Scikit-learn `Pipeline` combining **TF-IDF vectorization** and **Logistic Regression**.\n",
    "\n",
    "4. **Grid Search for Hyperparameter Optimization**\n",
    "\n",
    "   * Conducted `GridSearchCV` across TF-IDF features and logistic regression regularization strength (`C`).\n",
    "   * Best config: `max_features=10000`, `ngram_range=(1,2)`, `C=1`.\n",
    "\n",
    "5. **Model Evaluation**\n",
    "\n",
    "   * **Test Accuracy:** 0.8936\n",
    "   * **ROC AUC Score:** 0.9564\n",
    "   * Provided full classification report and confusion matrix.\n",
    "\n",
    "6. **Model Interpretation**\n",
    "\n",
    "   * Extracted and displayed top positive and negative words by learned coefficients.\n",
    "\n",
    "7. **User Interaction**\n",
    "\n",
    "   * Developed an interactive command-line tool for live movie review classification.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Results Table\n",
    "\n",
    "| Model                       | Accuracy | File Name                                  | Any Brief Note                            |\n",
    "| --------------------------- | -------- | ------------------------------------------ | ----------------------------------------- |\n",
    "| Logistic Regression (Tuned) | 0.8936   | `4c-Sentiment-Analysis-Scikit-Learn.ipynb` | GridSearchCV-tuned; high ROC AUC (0.9564) |\n",
    "\n",
    "> üí° *This model matches the best performance seen in previous notebooks, with the added benefit of interpretability and interactive use.*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ubCg1pJQhjf2",
   "metadata": {
    "id": "ubCg1pJQhjf2"
   },
   "source": [
    "# Full Python Script: IMDB Sentiment Classification (Scikit-learn Pipeline)\n",
    "\n",
    "‚úÖ The code has been updated to include your interactive review prediction function. You can now enter reviews manually, and the model will classify them as positive or negative with confidence scores. Let me know if you‚Äôd like a web interface or GUI version next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "KEMW5giyh2M6",
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1748530490987,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "KEMW5giyh2M6"
   },
   "outputs": [],
   "source": [
    "# # Mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "_47xqKa_hjHp",
   "metadata": {
    "executionInfo": {
     "elapsed": 9889,
     "status": "ok",
     "timestamp": 1748530500880,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "_47xqKa_hjHp"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "t96vJrrmhylJ",
   "metadata": {
    "executionInfo": {
     "elapsed": 30920,
     "status": "ok",
     "timestamp": 1748530531799,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "t96vJrrmhylJ"
   },
   "outputs": [],
   "source": [
    "# 1. Load Data\n",
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Download and extract dataset\n",
    "if not os.path.exists(\"aclImdb\"):\n",
    "    urllib.request.urlretrieve(url, \"aclImdb_v1.tar.gz\")\n",
    "    with tarfile.open(\"aclImdb_v1.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall()\n",
    "\n",
    "# Function to read reviews\n",
    "def load_imdb_data(data_dir):\n",
    "    data = {\"review\": [], \"sentiment\": []}\n",
    "    for label in [\"pos\", \"neg\"]:\n",
    "        sentiment = 1 if label == \"pos\" else 0\n",
    "        path = os.path.join(data_dir, label)\n",
    "        for file in os.listdir(path):\n",
    "            with open(os.path.join(path, file), encoding=\"utf-8\") as f:\n",
    "                data[\"review\"].append(f.read())\n",
    "                data[\"sentiment\"].append(sentiment)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "train_df = load_imdb_data(\"aclImdb/train\")\n",
    "test_df = load_imdb_data(\"aclImdb/test\")\n",
    "df = pd.concat([train_df, test_df])\n",
    "df = shuffle(df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "SMJy5GENhyhP",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1748530531819,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "SMJy5GENhyhP"
   },
   "outputs": [],
   "source": [
    "# 2. Train-Test Split\n",
    "X = df['review']\n",
    "y = df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9LeCRaOHiJgn",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1748530531820,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "9LeCRaOHiJgn"
   },
   "outputs": [],
   "source": [
    "# 3. Pipeline Creation\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(solver='liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "INokLuP2iOSR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 455714,
     "status": "ok",
     "timestamp": 1748530987531,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "INokLuP2iOSR",
    "outputId": "08cd35c9-06e9-4785-9202-010a8a141a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Best Parameters: {'clf__C': 1, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2)}\n",
      "Best CV Accuracy: 0.8939499923676283\n"
     ]
    }
   ],
   "source": [
    "# 4. Hyperparameter Tuning\n",
    "grid_params = {\n",
    "    'tfidf__max_features': [5000, 10000],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'clf__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipeline, grid_params, cv=3, n_jobs=-1, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", gs.best_params_)\n",
    "print(\"Best CV Accuracy:\", gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YSfFX3Uqp6fb",
   "metadata": {
    "id": "YSfFX3Uqp6fb"
   },
   "source": [
    "The result above is from a **grid search cross-validation (GridSearchCV)** process applied to this sentiment analysis pipeline. Here's a breakdown of what it means:\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Line-by-Line Explanation:\n",
    "\n",
    "#### **`Fitting 3 folds for each of 12 candidates, totalling 36 fits`**\n",
    "\n",
    "* You're using **3-fold cross-validation** (i.e., the training set is split into 3 parts, and each is used once as a validation set while the others are used for training).\n",
    "* You have **12 hyperparameter combinations** (candidates) to test.\n",
    "* Therefore, **36 model fits** (12 combinations √ó 3 folds) are performed.\n",
    "\n",
    "---\n",
    "\n",
    "#### **`Best Parameters: {'clf__C': 1, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2)}`**\n",
    "\n",
    "* These are the best hyperparameters found:\n",
    "\n",
    "  * `clf__C: 1`: The regularization strength for the Logistic Regression classifier. A moderate value, balancing bias and variance.\n",
    "  * `tfidf__max_features: 10000`: The TF-IDF vectorizer will use the top 10,000 most informative words.\n",
    "  * `tfidf__ngram_range: (1, 2)`: Both unigrams and bigrams (single words and two-word phrases) are included in the features.\n",
    "\n",
    "---\n",
    "\n",
    "#### **`Best CV Accuracy: 0.8939499923676283`**\n",
    "\n",
    "* The **cross-validated accuracy score** of the model using the best parameters above is approximately **89.4%**.\n",
    "* This score is based only on the training data split into 3 folds ‚Äî it gives a reliable estimate of how well the model is expected to perform on unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary:\n",
    "\n",
    "This result tells you that after testing 12 different combinations of parameters for your sentiment classification pipeline:\n",
    "\n",
    "* The best model includes both unigrams and bigrams, limits features to 10,000, and uses a regularization strength of 1.\n",
    "* It achieves nearly **89.4% accuracy** in cross-validation, suggesting strong generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7w9Z0SybiRes",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5774,
     "status": "ok",
     "timestamp": 1748530993302,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "7w9Z0SybiRes",
    "outputId": "d0c28a53-8653-4664-ad46-d805ba88cc14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Test Accuracy: 0.9\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4469  531]\n",
      " [ 469 4531]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      5000\n",
      "           1       0.90      0.91      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.96458336\n"
     ]
    }
   ],
   "source": [
    "# 5. Evaluate on Test Set\n",
    "best_model = gs.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nBest Model Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mMaqW17OrGtm",
   "metadata": {
    "id": "mMaqW17OrGtm"
   },
   "source": [
    "This is a comprehensive evaluation of the **best-performing sentiment analysis model** on the **test dataset** of 10,000 IMDB reviews. Let's break down the results:\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ **1. Best Model Test Accuracy: `0.90`**\n",
    "\n",
    "* The model correctly classified **90% of all test reviews** (both positive and negative).\n",
    "* Out of 10,000 test samples, **9,000 were predicted correctly**, and **1,000 were misclassified**.\n",
    "\n",
    "---\n",
    "\n",
    "### üìâ **2. Confusion Matrix:**\n",
    "\n",
    "```\n",
    "[[4469  531]\n",
    " [ 469 4531]]\n",
    "```\n",
    "\n",
    "|                         | Predicted Negative (0) | Predicted Positive (1) |\n",
    "| ----------------------- | ---------------------- | ---------------------- |\n",
    "| **Actual Negative (0)** | 4469 (True Negative)   | 531 (False Positive)   |\n",
    "| **Actual Positive (1)** | 469 (False Negative)   | 4531 (True Positive)   |\n",
    "\n",
    "#### Interpretation:\n",
    "\n",
    "* **4469 reviews** were correctly identified as negative.\n",
    "* **4531 reviews** were correctly identified as positive.\n",
    "* **531 negative reviews** were wrongly classified as positive.\n",
    "* **469 positive reviews** were wrongly classified as negative.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä **3. Classification Report:**\n",
    "\n",
    "| Class                | Precision | Recall | F1-Score | Support |\n",
    "| -------------------- | --------- | ------ | -------- | ------- |\n",
    "| 0 (Negative)         | 0.91      | 0.89   | 0.90     | 5000    |\n",
    "| 1 (Positive)         | 0.90      | 0.91   | 0.90     | 5000    |\n",
    "| **Overall Accuracy** |           |        | **0.90** | 10000   |\n",
    "\n",
    "#### Metrics:\n",
    "\n",
    "* **Precision**: Of all reviews predicted as a class, how many were correct.\n",
    "* **Recall**: Of all actual reviews of a class, how many were captured.\n",
    "* **F1-Score**: The harmonic mean of precision and recall ‚Äî a balanced measure.\n",
    "\n",
    "##### Balanced performance:\n",
    "\n",
    "* The model performs **similarly well** on both positive and negative reviews, with F1-scores of **0.90**.\n",
    "* There's **no significant bias** toward either class, which is ideal.\n",
    "\n",
    "---\n",
    "\n",
    "### üìà **4. ROC AUC Score: `0.9646`**\n",
    "\n",
    "* **ROC AUC** (Receiver Operating Characteristic - Area Under Curve) measures the model's ability to distinguish between the classes.\n",
    "* A value of **0.9646** is **excellent** (closer to 1 means better separability).\n",
    "\n",
    "#### What it means:\n",
    "\n",
    "* The model has a **96.5% chance of ranking a randomly chosen positive review higher than a negative one**.\n",
    "* This suggests the model outputs strong, confident probabilities ‚Äî not just good hard predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Summary:\n",
    "\n",
    "* **90% accuracy** on test data means the model generalizes well.\n",
    "* **Balanced precision and recall** across both classes.\n",
    "* **High ROC AUC** shows strong discriminative ability.\n",
    "* Only \\~5‚Äì6% of each class was misclassified ‚Äî overall, a **very effective sentiment classifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lZKxwtPAiSiE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1748530993327,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "lZKxwtPAiSiE",
    "outputId": "5a5d7b11-b141-45d1-f5dc-07e8d8603976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Positive Words:\n",
      "['great' 'excellent' 'amazing' 'perfect' 'wonderful' 'today' 'fun' 'loved'\n",
      " 'brilliant' 'hilarious' 'best' 'superb' 'the best' 'definitely'\n",
      " 'enjoyable' 'especially' 'bit' 'fantastic' 'favorite' 'enjoyed']\n",
      "\n",
      "Top Negative Words:\n",
      "['worst' 'bad' 'awful' 'boring' 'the worst' 'poor' 'waste' 'terrible'\n",
      " 'nothing' 'worse' 'dull' 'horrible' 'stupid' 'poorly' 'disappointing'\n",
      " 'unfortunately' 'lame' 'annoying' 'disappointment' 'fails']\n"
     ]
    }
   ],
   "source": [
    "# 6. (Optional) View Top Words by Coefficient\n",
    "def show_top_features(vectorizer, classifier, n=20):\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "    coef = classifier.coef_.flatten()\n",
    "    top_pos = np.argsort(coef)[-n:]\n",
    "    top_neg = np.argsort(coef)[:n]\n",
    "\n",
    "    print(\"\\nTop Positive Words:\")\n",
    "    print(feature_names[top_pos][::-1])\n",
    "    print(\"\\nTop Negative Words:\")\n",
    "    print(feature_names[top_neg])\n",
    "\n",
    "show_top_features(best_model.named_steps['tfidf'], best_model.named_steps['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbUQj2ohn4JT",
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1748531914873,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "dbUQj2ohn4JT"
   },
   "outputs": [],
   "source": [
    "# import textwrap\n",
    "\n",
    "def predict_sentiment_interactive(pipeline, width=100):\n",
    "    while True:\n",
    "        review_text = input(\"\\nEnter a movie review (or type 'exit' to quit): \")\n",
    "        if review_text.lower() == 'exit':\n",
    "            print(\"Exiting sentiment analysis. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        prediction = pipeline.predict([review_text])[0]\n",
    "        probability = pipeline.predict_proba([review_text])[0]\n",
    "\n",
    "        sentiment = \"Positive üòä\" if prediction == 1 else \"Negative üòû\"\n",
    "        confidence = round(max(probability) * 100, 2)\n",
    "\n",
    "        # Wrap the text for display in notebook\n",
    "        wrapped_review = textwrap.fill(review_text, width=width)\n",
    "\n",
    "        print(\"\\nüìù Review:\")\n",
    "        print(wrapped_review)\n",
    "        print(f\"\\n‚úÖ Sentiment: {sentiment}\")\n",
    "        print(f\"üìä Confidence: {confidence}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "haACe_4clzR5",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1748531370324,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "haACe_4clzR5"
   },
   "outputs": [],
   "source": [
    "# # 7. Predict Sentiment from Manual Input\n",
    "\n",
    "# def predict_sentiment_interactive(pipeline):\n",
    "#     while True:\n",
    "#         review_text = input(\"\\nEnter a movie review (or type 'exit' to quit): \")\n",
    "#         if review_text.lower() == 'exit':\n",
    "#             print(\"Exiting sentiment analysis. Goodbye!\")\n",
    "#             break\n",
    "\n",
    "#         prediction = pipeline.predict([review_text])[0]\n",
    "#         probability = pipeline.predict_proba([review_text])[0]\n",
    "\n",
    "#         sentiment = \"Positive üòä\" if prediction == 1 else \"Negative üòû\"\n",
    "#         confidence = round(max(probability) * 100, 2)\n",
    "\n",
    "#         print(\"\\nüìù Review:\")\n",
    "#         print(review_text)\n",
    "#         print(f\"\\n‚úÖ Sentiment: {sentiment}\")\n",
    "#         print(f\"üìä Confidence: {confidence}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a4a67b",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1748530993343,
     "user": {
      "displayName": "Percy Landa",
      "userId": "00834250160249361181"
     },
     "user_tz": 420
    },
    "id": "21a4a67b",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# # 7. Predict Sentiment from Manual Input\n",
    "\n",
    "# def predict_sentiment_interactive(pipeline):\n",
    "#     while True:\n",
    "#         review_text = input(\"\\nEnter a movie review (or type 'exit' to quit): \")\n",
    "#         if review_text.lower() == 'exit':\n",
    "#             print(\"Exiting sentiment analysis. Goodbye!\")\n",
    "#             break\n",
    "\n",
    "#         prediction = pipeline.predict([review_text])[0]\n",
    "#         probability = pipeline.predict_proba([review_text])[0]\n",
    "\n",
    "#         sentiment = \"Positive üòä\" if prediction == 1 else \"Negative üòû\"\n",
    "#         confidence = round(max(probability) * 100, 2)\n",
    "\n",
    "#         print(f\"\\n‚úÖ Sentiment: {sentiment}\")\n",
    "#         print(f\"üìä Confidence: {confidence}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zPz9A_aBiZve",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zPz9A_aBiZve",
    "outputId": "e73b3bc9-d9b3-48e7-b4e8-f202460eadd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Review:\n",
      "HI there!\n",
      "\n",
      "‚úÖ Sentiment: Negative üòû\n",
      "üìä Confidence: 67.32%\n",
      "\n",
      "üìù Review:\n",
      "What a fantastic mobie!\n",
      "\n",
      "‚úÖ Sentiment: Positive üòä\n",
      "üìä Confidence: 96.07%\n",
      "\n",
      "üìù Review:\n",
      "What a fantastic movie! Are you kidding? I will not recommend it\n",
      "\n",
      "‚úÖ Sentiment: Positive üòä\n",
      "üìä Confidence: 72.06%\n"
     ]
    }
   ],
   "source": [
    "# üîç Run it\n",
    "predict_sentiment_interactive(best_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
